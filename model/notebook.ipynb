{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Set the path where to find the gathered images and show a single image to validate wether we are in the correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path = 'images/'\n",
    "im = Image.open(path + 'grape/grape-0.jpg')\n",
    "im.to_thumb(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable \"filenames\" that contains a listing of all paths to all files in the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "filenames = get_image_files(path)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify all images, to make sure none of them are corrupt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = verify_images(filenames)\n",
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to read-in the data for our modelling. First lets create our own DataLoaders object. This is done in FastAI by using the 'data block API'.\n",
    "\n",
    "### Class DataBlock\n",
    "- blocks\n",
    "    - Tuple where we specify what types we want for the independent (= what we are using to make predictions from) and dependent (= the categories for each image) variables.\n",
    "- get_items\n",
    "    - We have to tell FastAI how to get a list of images, this is our dataset. The get_image_files function takes a path, and returns a list of all of the images in that path.\n",
    "- splitter\n",
    "    - We want to split our training and validation sets randomly. The seed makes sure we always get the same random values each time we run this codeblock.\n",
    "- get_y\n",
    "    - y = the dependent variable = our labels. We tall FastAI to call the function parent_label to create the labels in our dataset based on the directory names. (In our case \"apple\", \"avocado\", \"apple, \"grape\" & \"orange\")\n",
    "- item_tfms\n",
    "    - We have to transform the images all in the same size, so that we can feed several images at once to the model. The function Resize(128) will resize all the images to 128x128 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our DataBlock object, we have to feed it the path to where it can find the data. In our case this is 'images/'.\n",
    "\n",
    "FastAI will do all the rest: loading the data into train/valid sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = fruits.dataloaders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, FastAI has a default batch_size of 64.\n",
    "\n",
    "### Random crop size\n",
    "Research shows, it's usually best to do a kind of random resized cropping. So every epoch, another random section of the image is chosen. So every epoch, the network focuses on a different part of the image. We give a min_scale, otherwise it is possible for the network to randomly select a very small piece.\n",
    "\n",
    "### Other augmentations\n",
    "We also rotate, flip and adjust the brightness to have more unique images to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = fruits.new(item_tfms=RandomResizedCrop(128, min_scale=0.5), batch_tfms=[Rotate(), Flip(), Brightness()])\n",
    "dls = fruits.dataloaders(path)\n",
    "dls.train.show_batch(max_n=8, nrows=2, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "We make use of the vgg19_bn network to do trasfer learning.\n",
    "We tried different pretrained CNN networks, and concluded that the vgg19_bn network gave the best result.\n",
    "\n",
    "We make use of 4 fine-tune iterations. 1 fine-tune means: train the randomly added layers for one epoch, with other layers frozen. Then unfreeze all of the layers and trains them all for the number of epochs requested.\n",
    "\n",
    "(We don't specify the learning rate: so the default is 1e-3 = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [accuracy, error_rate]\n",
    "our_out_of_the_box_model = cnn_learner(dls, vgg19_bn, loss_func=CrossEntropyLossFlat(), metrics=metrics )\n",
    "our_out_of_the_box_model.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance\n",
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(our_out_of_the_box_model)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_out_of_the_box_model.save('model')\n",
    "our_out_of_the_box_model.export()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c06389e76c84c699a49cfe7394424bbe58c0a7ced95a6065829c4b635b0d5e75"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('mlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
